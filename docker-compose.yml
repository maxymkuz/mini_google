version: "3.8"
services:
#  elasticsearch:
#    image: docker.elastic.co/elasticsearch/elasticsearch:7.4.0
#    container_name: elasticsearch
#    environment:
#      - xpack.security.enabled=false
#      - discovery.type=single-node
#    ulimits:
#      memlock:
#        soft: -1
#        hard: -1
#      nofile:
#        soft: 65536
#        hard: 65536
#    cap_add:
#      - IPC_LOCK
#    volumes:
#      - elasticsearch-data:/usr/share/elasticsearch/data
#    ports:
#      - 9200:9200
#      - 9300:9300

#  website:
#     build: ./website/
#     ports:
#       - 5000:5000
#     depends_on:
#       - elasticsearch
#      depends_on:
#        elasticsearch:
#          condition: service_healthy

  database_backend:
    build: ./database_backend/
#    command: "cargo run"
    #networks:
      #- frontend # set up a network that we can use across different containers
    ports:
     - 8080:8080
#    depends_on:
#      - elasticsearch
#    depends_on:
#      elasticsearch:
#        condition: service_healthy

volumes:
  cargo: {}
  target: {}
  elasticsearch-data:
    driver: local

#     lang_detect_python:
#       build: ./lang_detect_python/
#       volumes:
#         - ./lang_detect_python/:/usr/src/app/
#       ports:
#         - 5001:5001
#       environment:
#         PORT: 5001
#         FLASK_DEBUG: 1
#       restart: always
#
#     python_app:
#       build: ./python_app/
#      depends_on:
#        elasticsearch:
#          condition: service_healthy
#
#
#    rust_crawler:
#    build: ./rust_crawler/
#    command: --inp_file=urls.txt --out_file=out.txt --threads=4 --limit=200
#    volumes:
#          - cargo:/home/rust/.cargo
#          - target:/home/rust/src/target
#      depends_on:
#        elasticsearch:
#          condition: service_healthy
